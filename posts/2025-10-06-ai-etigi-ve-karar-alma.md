---
layout: post
title: "Yapay Zeka Etiği: Makineler Kime Göre Karar Vermeli?"
author: Evren Yazar
date: 2025-10-06 10:00:00 +0300
categories: [teknoloji, felsefe, gelecek]
---

# Yapay Zeka Kararlarının Derin Ahlaki İkilemleri

Yapay zeka sistemleri artık sadece veri analizi yapmıyor; kredi başvurularını onaylıyor, tıbbi teşhis koyuyor ve otonom araçlarda hayat-kurtarıcı anlık kararlar veriyor. Bu durum, bizi modern felsefenin en büyük sınavlarından biriyle karşı karşıya bırakıyor: **Algoritmalar kime göre 'doğru' kararı vermelidir?**

## Etik Çerçevenin Temelleri

Yapay zeka etiği genellikle üç ana felsefi akım üzerine inşa edilir:

1.  **Sonuç Odaklılık (Utilitarianism):** Kararın sonucunda en çok kişinin fayda sağlaması esas alınır. (Örn: Otonom araç kazasında en az hasar nerede olur?)
2.  **Kural Odaklılık (Deontology):** Belli kurallara ve evrensel görevlere uymak esas alınır. (Örn: Asla yalan söyleme kuralına uymak.)
3.  **Erdem Etiği (Virtue Ethics):** Kararı alan sistemin veya programcının sahip olması gereken erdemlere odaklanır.

## Karar Mekanizmalarındaki Yanlılık

Eğitim verilerindeki tarihsel, kültürel veya ırksal önyargılar, yapay zekanın kararlarına da sızar. Bir yapay zeka sistemi, eğer eğitildiği veri setinde belli bir grubu "daha riskli" görüyorsa, o gruba karşı ayrımcı kararlar verme potansiyeli taşır. Bu, sistemin kodunun değil, **insanlığın yansıttığı önyargının** bir sonucudur.

Yapay zeka etiği, sadece makinelerin nasıl çalıştığını değil, aynı zamanda **insanların nasıl bir toplum istediğini** sorgular.